## 1. Selenium을 이용한 YOGIYO  Web Crawling

 

#파이썬 라이브러리(사전  설치필요)**

import time

import pickle

import pandas as pd

from tqdm import  tqdm    #상태바 나타내는 라이브러리

from tqdm import trange

import warnings

warnings.filterwarnings('ignore')

 

 

**#** **크롤링 패키지**

import requests

from selenium import  webdriver

 

 

**#****요기요에서 제공하는 파스쿠찌매장(서울) 주소 리스트**

test_list = ['서울 종로구 대학로 142', '서울시  종로구 관수동 3-1', '서울시 종로구 세종대로 23길 54', … , '서울특별시 강남구 도곡동 953 다림빌딩']

 

 

**#****크롤링한 총 결과 담을 데이터프레임 생성(가져올 컬럼 : 매장이름, 사용자  아이디, 시킨 메뉴, 리뷰글, 총 평점, 맛 평점, 양  평점, 배달 평점, 날짜)**

df_result =  pd.DataFrame(columns=['Restaurant','UserID','Menu','Review',

​                                        'Total','Taste','Quantity','Delivery','Date'])

 

 

**#****웹 드라이버(Chrome,  Firefox,... 설치필요)**

**#****크롬 :** [**http://chromedriver.chromium.org/downloads**](http://chromedriver.chromium.org/downloads)

**#(‘****크롬 웹 드라이버저장된주소\chromedriver.exe’)**

wd =  webdriver.Chrome('C:\chromedriver.exe')

 

 

 

 

**#Chrome webdriver -** **요기요 페이지 크롤링 실행**

for i in test_list: 

​    wd.get('https://www.yogiyo.co.kr/')

​    print('요기요 페이지 시작’')

​    time.sleep(1.5)

​    

​    **#****요기요 페이지 주소창에 test_list입력**

​     wd.find_element_by_xpath('//*[@id="search"]/div/form/input').click()

​     wd.find_element_by_xpath('//*[@class="btn-search-location-cancel  btn-search-location btn btn-default"]').click()

​     wd.find_element_by_name('address_input').send_keys(i)

​     wd.find_element_by_xpath('//*[@id="button_search_address"]').click()

​    time.sleep(2)

 

 

​    **#****파스쿠찌 이미지로 파스쿠찌 리뷰 찾기**

​     wd.find_element_by_xpath('//*[@style="background-image:  url(\'/media/franchise_logos/파스쿠치_20180419_Franchise이미지약정서_crop_200x200.png\'),  url(\'image/default_restaurant_logo.png\');"]').click()

​    time.sleep(1.5)

 

​    

​    **#****해당 파스쿠찌 매장의 클린리뷰창** 

​     wd.find_element_by_xpath('//*[@id="content"]/div[2]/div[1]/ul/li[2]/a').click()

​    wd.find_elements_by_css_selector('#review  > li.list-group-item.star-point.ng-scope')

 

 

​    **#****리뷰 불러오기**

​    review_count =  int(wd.find_element_by_xpath('//*[@id="content"]/div[2]/div[1]/ul/li[2]/a/span').text)

​    click_count = int((review_count/10))

​    print('모든 리뷰 불러오기 시작')

 

 

​    **#****더보기 클릭**

​    for _ in trange(click_count):

​        try:

​             wd.find_element_by_class_name('btn-more').click()

​            time.sleep(2)

​        except Exception as e:

​            pass

​    print('모든 리뷰 보기 완료’')

​    time.sleep(2)

 

​    reviews =  wd.find_elements_by_css_selector('#review >  li.list-group-item.star-point.ng-scope')

​    time.sleep(2)

 

 

**#****크롤링한 한 지점의 결과 담을 데이터프레임**

​    df =  pd.DataFrame(columns=['Restaurant','UserID','Menu','Review',

​                                        'Total','Taste','Quantity','Delivery','Date'])

 

 

**#****해당 지점의 리뷰 수 만큼 데이터를 가져옴(가져올 컬럼 : 매장이름, 사용자  아이디, 시킨 메뉴, 리뷰글, 총 평점, 맛 평점, 양  평점, 배달 평점, 날짜)**

​    for review in tqdm(reviews):  

​        try:

​            df.loc[len(df)] = { 

​                                 'Restaurant':wd.find_element_by_class_name('restaurant-name').text,

​                                'UserID':review.find_element_by_css_selector('span.review-id.ng-binding').text,

​                                 'Menu':review.find_element_by_css_selector('div.order-items.default.ng-binding').text,

​                                 'Review':review.find_element_by_css_selector('p').text,

​                                 'Total':str(len(review.find_elements_by_css_selector('div >  span.total > span.full.ng-scope'))),

​                                 'Taste':review.find_element_by_css_selector('div:nth-child(2) > div  > span.category > span:nth-child(3)').text,

​                                 'Quantity':review.find_element_by_css_selector('div:nth-child(2) >  div > span.category > span:nth-child(6)').text,

​                                 'Delivery':review.find_element_by_css_selector('div:nth-child(2) >  div > span.category > span:nth-child(9)').text,

​                                 'Date':review.find_element_by_css_selector('div:nth-child(1) >  span.review-time.ng-binding').text,

 

​    }

​        except Exception as e:

​            print('리뷰 페이지 에러')

​            print(e)

​            pass

​    time.sleep(2)        

​    print('크롤링 완료')

​    time.sleep(2)

 

 

​    **#****크롤링 결과 피클에 입력**

​    pickle.dump(df,  open('./data/first.pkl','wb'))

 

 

​    **#****피클에서 가져오기**

​    df =  pickle.load(open('./data/first.pkl','rb'))

 

 

​    **#****데이터 프레임 결합**

​    df_result = pd.concat([df_result,df]) 

​    display(df_result)

 

![img](file:///C:/Users/김란아/AppData/Local/Temp/msohtmlclip1/01/clip_image002.gif)

![img](file:///C:/Users/김란아/AppData/Local/Temp/msohtmlclip1/01/clip_image004.gif)

![img](file:///C:/Users/김란아/AppData/Local/Temp/msohtmlclip1/01/clip_image006.gif)

![img](file:///C:/Users/김란아/AppData/Local/Temp/msohtmlclip1/01/clip_image008.gif)

 

**#****크롤링 총 결과 데이터 프레임  CSV파일로 저장**

df_result.to_csv("C:\example\clawringexample_20190516_True.csv",header=True,index=True)

df_result.to_csv("C:\example\clawringexample_20190516_False.csv",header=False,index=False)